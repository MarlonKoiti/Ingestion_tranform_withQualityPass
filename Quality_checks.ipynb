{
	"metadata": {
		"kernelspec": {
			"name": "glue_pyspark",
			"display_name": "Glue PySpark",
			"language": "python"
		},
		"language_info": {
			"name": "Python_Glue_Session",
			"mimetype": "text/x-python",
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"pygments_lexer": "python3",
			"file_extension": ".py"
		}
	},
	"nbformat_minor": 4,
	"nbformat": 4,
	"cells": [
		{
			"cell_type": "code",
			"source": "from pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col,regexp_replace\nimport pandas as pd\nfrom datetime import datetime",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 51,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "# Inicialize a sessão Spark\nspark = SparkSession.builder \\\n    .appName(\"QualityAnalyses\") \\\n    .getOrCreate()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 5,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "# Carregar seus dados em um DataFrame Spark\ninput_s3_path_bancos = \"s3://172684736408-trusted/Bancos/*.parquet\"\ninput_s3_path_empregados = \"s3://172684736408-trusted/Empregados/*.parquet\"\ninput_s3_path_reclamacoes = \"s3://172684736408-trusted/Reclamações/*.parquet\"\n\ndf_bancos = spark.read.option(\"encoding\", \"UTF-8\").parquet(input_s3_path_bancos)\ndf_empregados = spark.read.option(\"encoding\", \"UTF-8\").parquet(input_s3_path_empregados)\ndf_reclamacoes = spark.read.option(\"encoding\", \"UTF-8\").parquet(input_s3_path_reclamacoes)\n",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 9,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "# Verificar qualidade da coluna \"CNPJ\" em df_bancos\ndef verificar_qualidade_cnpj(df):\n    # Filtrar valores CNPJ zerados\n    cnpj_zerados = df[df['CNPJ'] == 0]  # Supondo que um CNPJ zerado seja representado por 14 zeros\n    cnpj_zerados['Data'] = datetime.today().date()\n    \n    if not cnpj_zerados.empty:\n        return cnpj_zerados\n    else:\n        df = pd.DataFrame(columns=['CNPJ', 'Nome'])  # Retorna um dataframe vazio\n        df.loc[0] = ['null', 'null']\n        df['Data'] = datetime.today().date()\n        return df\n\n# Verificar qualidade da coluna \"Nome\" em df_reclamacoes\ndef verificar_qualidade_nome(df):\n    # Verificar valores nulos na coluna Nome\n    nulos = df[df['Nome'].isnull()]\n    nulos['Data'] = datetime.today().date()\n    \n    if not nulos.empty:\n        return nulos\n    else:\n        df = pd.DataFrame(columns=['Nome', 'indice', 'qtd_total_reclamacoes', 'qtd_total_clientes'])\n        df.loc[0] = ['null', 'null', 'null', 'null']\n        df['Data'] = datetime.today().date()\n        return df \n\n# Verificar qualidade da coluna \"Nome\" em df_empregados\ndef verificar_qualidade_nome_empregados(df):\n    # Verificar valores em branco na coluna Nome\n    em_branco = df[df['Nome'].str.strip() == \"\"]\n    em_branco['Data'] = datetime.today().date()\n    \n    if not em_branco.empty:\n        return em_branco\n    else:\n        df = pd.DataFrame(columns=['Nome', 'satisfacao_salario', 'satisfacao_empregado'])\n        df.loc[0] = ['null', 'null', 'null']\n        df['Data'] = datetime.today().date()\n        return df\n\n# Função para escrever um dataframe em um bucket S3\ndef escrever_dataframe_s3(df, bucket_name, object_key):\n    csv_buffer = StringIO()\n    df.to_csv(csv_buffer, index=False)\n    \n    s3 = boto3.client('s3')\n    s3.put_object(Bucket=bucket_name, Key=object_key, Body=csv_buffer.getvalue())\n\n# Chamando as funções de verificação\ndf_qualidade_cnpj = verificar_qualidade_cnpj(df_bancos.toPandas())\ndf_qualidade_nome = verificar_qualidade_nome(df_reclamacoes.toPandas())\ndf_qualidade_nome_empregados = verificar_qualidade_nome_empregados(df_empregados.toPandas())\n\n#df['Data'] = datetime.today().date()\n\n#df_qualidade_cnpj.write.format(\"parquet\").mode(\"overwrite\").option(\"path\", f\"{input_s3_path_reclamacoes}\").save()\n#df_qualidade_nome.write.format(\"parquet\").mode(\"overwrite\").option(\"path\", f\"{input_s3_path_reclamacoes}\").save()\n#df_qualidade_nome_empregados.write.format(\"parquet\").mode(\"overwrite\").option(\"path\", f\"{input_s3_path_reclamacoes}\").save()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 53,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df_qualidade_cnpj = spark.createDataFrame(df_qualidade_cnpj)\ndf_qualidade_nome = spark.createDataFrame(df_qualidade_nome)\ndf_qualidade_nome_empregados = spark.createDataFrame(df_qualidade_nome_empregados)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 55,
			"outputs": [
				{
					"name": "stdout",
					"text": "TypeError: data is already a DataFrame\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "jdbc_url = \"jdbc:sqlserver://database.cq2cmdvszmas.us-east-1.rds.amazonaws.com:1433\"\n\n\nconnection_mssql_options = {\n    \"url\": jdbc_url,\n    \"user\": \"admin\",\n    \"password\": \"admin1234\"}\n\ntb = \"ativ.dbo.banco_log\"\ndf_qualidade_cnpj.write.mode(\"overwrite\").jdbc(url=jdbc_url, \\\n                                                  table = tb, properties = connection_mssql_options)\n\ntb = \"ativ.dbo.empregados_log\"\ndf_qualidade_nome_empregados.write.mode(\"overwrite\").jdbc(url=jdbc_url, \\\n                                                  table = tb, properties = connection_mssql_options)\n\ntb = \"ativ.dbo.reclamacoes_log\"\ndf_qualidade_nome.write.mode(\"overwrite\").jdbc(url=jdbc_url, \\\n                                                  table = tb, properties = connection_mssql_options)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 57,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		}
	]
}